{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6726f223-70a0-436d-8bc6-17fe5be34b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-23 07:31:59.416 WARNING streamlit.runtime.caching.cache_data_api: No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-23 07:31:59.423 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:00.480 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Keerthana\\anaconda3.12\\envs\\FYP\\Lib\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-23 07:32:00.481 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:00.483 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:00.995 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:00.995 Thread 'Thread-5': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.230 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.262 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.278 No runtime found, using MemoryCacheStorageManager\n",
      "2025-03-23 07:32:34.282 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.285 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.289 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.625 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.638 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.642 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.661 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.689 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.695 Session state does not function when running a script without `streamlit run`\n",
      "2025-03-23 07:32:34.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.721 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.722 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.723 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.726 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.730 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-23 07:32:34.734 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# ---------------------------\n",
    "# Load data and models\n",
    "# ---------------------------\n",
    "@st.cache_data\n",
    "def load_data():\n",
    "    return pd.read_csv('./data/categorized_specializations.csv')\n",
    "\n",
    "# ---------------------------\n",
    "# Function to Load Models\n",
    "# ---------------------------\n",
    "@st.cache_resource\n",
    "def load_models():\n",
    "    \n",
    "    models = {\n",
    "        \"rf_specialization\": joblib.load(\"models/major_models/rf_specialization.pkl\"),\n",
    "        \"rf_university\": joblib.load(\"models/university_models/rf_university.pkl\"),\n",
    "        \"xgb_specialization\": xgb.XGBClassifier(),\n",
    "        \"label_encoders_specialization\": joblib.load(\"models/major_models/label_encoders_specialization.pkl\"),\n",
    "        \"label_encoders_university\": joblib.load(\"models/university_models/label_encoders_university.pkl\"),\n",
    "        \"scaler_specialization\": joblib.load(\"models/major_models/scaler_specialization.pkl\"),\n",
    "        \"scaler_university\": joblib.load(\"models/university_models/scaler_university.pkl\"),\n",
    "        \"svd_specialization\": joblib.load(\"models/major_models/svd_specialization.pkl\"),\n",
    "        \"knn_specialization\": joblib.load(\"models/major_models/knn_specialization.pkl\"),\n",
    "        \"svd_university\": joblib.load(\"models/university_models/svd_univ.pkl\"),\n",
    "        \"knn_university\": joblib.load(\"models/university_models/knn_univ.pkl\"),\n",
    "        \"le_y_specialization\": joblib.load(\"models/major_models/le_y_spec.pkl\"),\n",
    "        \"le_y_university\": joblib.load(\"models/university_models/le_y_univ.pkl\"),\n",
    "        \"one_hot_columns_university\": joblib.load(\"models/university_models/one_hot_columns_university.pkl\")\n",
    "    }\n",
    "    \n",
    "    # Load the XGB model from JSON for specialization\n",
    "    models[\"xgb_specialization\"].load_model(\"models/major_models/xgb_specialization.json\")\n",
    "    \n",
    "    return models\n",
    "\n",
    "# Load models and data\n",
    "models = load_models()\n",
    "df = load_data()\n",
    "\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "        body {\n",
    "            background-color: #1A1A2E; /* Dark navy blue */\n",
    "            color: white; /* Light gray text */\n",
    "        }\n",
    "        .stApp {\n",
    "            background-color: #1A1A2E;\n",
    "        }\n",
    "        .stMarkdown {\n",
    "            color: white;\n",
    "        }\n",
    "        .stDataFrame, .stTable {\n",
    "            background-color: #16213E; /* Slightly lighter blue */\n",
    "            color: white;\n",
    "            border-radius: 10px;\n",
    "            padding: 10px;\n",
    "        }\n",
    "        .stButton > button {\n",
    "            background-color: #0F3460; /* Deep blue */\n",
    "            color: white;\n",
    "            border-radius: 8px;\n",
    "            padding: 10px 15px;\n",
    "            font-size: 16px;\n",
    "        }\n",
    "        .stButton > button:hover {\n",
    "            background-color: #533483; /* Purple hover effect */\n",
    "        }\n",
    "        .stSelectbox, .stTextInput, .stNumberInput, .stRadio, .stSlider {\n",
    "            background-color: #16213E !important;\n",
    "            color: white !important;\n",
    "            border-radius: 8px;\n",
    "        }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "# Preprocessing function\n",
    "# ---------------------------\n",
    "def preprocess_input(data, categorical_features, numerical_features, label_encoders, scaler, feature_order, one_hot_columns=None):\n",
    "    df_input = pd.DataFrame([data])\n",
    "    # Encode categorical features\n",
    "    for col in categorical_features:\n",
    "        if col in label_encoders and df_input[col].iloc[0] in label_encoders[col].classes_:\n",
    "            df_input[col] = label_encoders[col].transform([df_input[col].iloc[0]])[0]\n",
    "        else:\n",
    "            df_input[col] = -1  # Handle missing/unknown values\n",
    "    # Scale numerical features\n",
    "    df_input[numerical_features] = scaler.transform(df_input[numerical_features])\n",
    "    if one_hot_columns:\n",
    "        df_input = df_input.reindex(columns=feature_order + one_hot_columns, fill_value=0)\n",
    "        state_val = data.get(\"univ_state\", None)\n",
    "        state_column = f\"univ_state_{state_val}\"\n",
    "        if state_val and state_val != \"Select All\" and state_column in one_hot_columns:\n",
    "            df_input[state_column] = 1\n",
    "    return df_input\n",
    "\n",
    "# ---------------------------\n",
    "# Hybrid recommendation for Specialization (unchanged)\n",
    "# ---------------------------\n",
    "def hybrid_recommendation(input_df, rf_model, xgb_model, collab_model, svd_model, label_encoder, is_university=False, state=None):\n",
    "    # Content-based predictions\n",
    "    rf_probs = rf_model.predict_proba(input_df)[0]\n",
    "    xgb_probs = xgb_model.predict_proba(input_df)[0]\n",
    "\n",
    "    # Ensemble: Averaging the probabilities\n",
    "    content_probs = (rf_probs + xgb_probs) / 2\n",
    "    \n",
    "    try:\n",
    "        transformed_features = svd_model.transform(input_df)\n",
    "        similar_users = collab_model.kneighbors(transformed_features, return_distance=False)\n",
    "        collab_probs = np.zeros_like(content_probs)\n",
    "        # (Using content_model.predict_proba on the same input as a fallback)\n",
    "        for idx in similar_users.flatten():\n",
    "            collab_probs += content_probs  \n",
    "#            collab_probs += content_model.predict_proba([input_df.iloc[0]])[0]\n",
    "        collab_probs /= len(similar_users.flatten()) if len(similar_users.flatten()) > 0 else 1\n",
    "    except Exception as e:\n",
    "        collab_probs = np.zeros_like(content_probs)\n",
    "    \n",
    "    alpha = np.var(content_probs) / (np.var(content_probs) + np.var(collab_probs) + 1e-5)\n",
    "    final_probs = (content_probs * alpha) + (collab_probs * (1 - alpha))\n",
    "    \n",
    "    top_n = 5 if not is_university else 3\n",
    "    top_indices = np.argsort(final_probs)[-top_n:][::-1]\n",
    "    \n",
    "    final_recommendations = label_encoder.inverse_transform(top_indices)\n",
    "    return final_recommendations\n",
    "\n",
    "# ---------------------------\n",
    "# Hybrid University Recommendation (with Collaborative Filtering)\n",
    "# ---------------------------\n",
    "def hybrid_university_recommendation(input_df, content_model, collab_model, svd_model, label_encoder,\n",
    "                          is_university=False, state=None, one_hot_columns=None):\n",
    "    if is_university:\n",
    "        # If no particular state is selected (\"Select All\"), average over all possible state one-hot encodings.\n",
    "        if state is None and one_hot_columns is not None:\n",
    "            probs_list = []\n",
    "            for state_col in one_hot_columns:\n",
    "                temp_df = input_df.copy()\n",
    "                # Ensure all state columns are zero then set the current one-hot state to 1.\n",
    "                temp_df[one_hot_columns] = 0\n",
    "                temp_df[state_col] = 1\n",
    "                try:\n",
    "                    probs = content_model.predict_proba(temp_df)[0]\n",
    "                except Exception as e:\n",
    "                    probs = content_model.predict(temp_df)\n",
    "                probs_list.append(probs)\n",
    "            content_probs = np.mean(probs_list, axis=0)\n",
    "        else:\n",
    "            # If a specific state is selected, use the input_df (which already has the proper one-hot column set)\n",
    "            try:\n",
    "                content_probs = content_model.predict_proba(input_df)[0]\n",
    "            except Exception as e:\n",
    "                content_probs = content_model.predict(input_df)\n",
    "        \n",
    "        # Collaborative Filtering: Use KNN and SVD models to generate collaborative probabilities\n",
    "        try:\n",
    "            transformed_features = svd_model.transform(input_df)\n",
    "            similar_users = collab_model.kneighbors(transformed_features, return_distance=False)\n",
    "            collab_probs = np.zeros_like(content_probs)\n",
    "            # Aggregate the collaborative predictions based on similar users\n",
    "            for idx in similar_users.flatten():\n",
    "                collab_probs += content_model.predict_proba([input_df.iloc[0]])[0]\n",
    "            collab_probs /= len(similar_users.flatten()) if len(similar_users.flatten()) > 0 else 1\n",
    "        except Exception as e:\n",
    "            collab_probs = np.zeros_like(content_probs)\n",
    "        \n",
    "        # Combine content-based and collaborative-based predictions\n",
    "        alpha = np.var(content_probs) / (np.var(content_probs) + np.var(collab_probs) + 1e-5)\n",
    "        final_probs = (content_probs * alpha) + (collab_probs * (1 - alpha))\n",
    "        \n",
    "        # Select top N universities\n",
    "        top_n = 3  # Recommend top 3 universities\n",
    "        \n",
    "        top_indices = np.argsort(final_probs)[-top_n:][::-1]\n",
    "        final_recommendations = label_encoder.inverse_transform(top_indices)\n",
    "        \n",
    "        # If a specific state was requested, filter the recommendations accordingly.\n",
    "        if state is not None:\n",
    "            filtered_recommendations = [rec for rec in final_recommendations \n",
    "                                        if rec in df[df['univ_state'] == state]['univName'].values]\n",
    "            if len(filtered_recommendations) < top_n:\n",
    "                st.warning(f\"âš ï¸ Only {len(filtered_recommendations)} universities found in {state}. Expanding recommendations.\")\n",
    "                filtered_recommendations = final_recommendations\n",
    "            return filtered_recommendations\n",
    "        \n",
    "        return final_recommendations\n",
    "\n",
    "# Helper function to compute aggregated statistics for a given specialization\n",
    "def display_specialization_stats(specialization, df):\n",
    "    subset = df[df['specialization_category'] == specialization]\n",
    "    if subset.empty:\n",
    "        return None\n",
    "    stats = {\n",
    "        \"ðŸ”¢ Number of Students\": subset.shape[0],\n",
    "        \"ðŸ“Š Avg Normalized CGPA\": round(subset['normalized_cgpa'].mean(), 2),\n",
    "        \"ðŸ“ Avg TOEFL Score\": round(subset['toeflScore'].mean(), 2),\n",
    "        \"ðŸ—£ Avg GRE Verbal\": round(subset['greV'].mean(), 2),\n",
    "        \"ðŸ“ˆ Avg GRE Quant\": round(subset['greQ'].mean(), 2),\n",
    "        \"ðŸ“‰ Avg GRE Analytical\": round(subset['greA'].mean(), 2),\n",
    "#        \"ðŸ”¬ Avg Research Exp (yrs)\": round(subset['researchExp'].mean(), 2),\n",
    "#        \"ðŸ­ Avg Industry Exp (yrs)\": round(subset['industryExp'].mean(), 2),\n",
    "#        \"ðŸ’¼ Avg Internship Exp (yrs)\": round(subset['internExp'].mean(), 2)\n",
    "    }\n",
    "    return pd.DataFrame(stats.items(), columns=[\"Metric\", \"Value\"])\n",
    "\n",
    "# ---------------------------\n",
    "# Streamlit UI\n",
    "# ---------------------------\n",
    "st.title(\"ðŸŽ“ University & Major Recommender System\")\n",
    "# Navigation Sidebar\n",
    "page = st.sidebar.radio(\"Select a Page\", [\"Home\", \"Major Recommendation\", \"University Recommendation\"])\n",
    "\n",
    "if page == \"Home\":\n",
    "    st.header(\"Welcome to the Recommender System\")\n",
    "    st.write(\"\"\"\n",
    "    This system helps you find the most suitable **courses** and **universities** for your academic and professional background.\n",
    "    \n",
    "    - Go to **Course Recommendation** to find potential academic majors.\n",
    "    - Go to **University Recommendation** to find the best universities based on your profile.\n",
    "    \"\"\")\n",
    "\n",
    "# Streamlit UI for Course Recommendation\n",
    "elif page == \"Major Recommendation\":\n",
    "    st.header(\"ðŸ“Œ Major Recommendation\")\n",
    "    user_input = {\n",
    "        \"major\": st.selectbox(\"Major\", sorted(df['major'].unique())),\n",
    "        \"researchExp\": st.number_input(\"Research Experience (years)\", min_value=0.0, step=0.1),\n",
    "        \"industryExp\": st.number_input(\"Industry Experience (years)\", min_value=0.0, step=0.1),\n",
    "        \"toeflScore\": st.number_input(\"TOEFL Score\", min_value=0, max_value=120),\n",
    "        \"internExp\": st.number_input(\"Internship Experience (years)\", min_value=0.0, step=0.1),\n",
    "        \"greV\": st.number_input(\"GRE Verbal Score\", min_value=130, max_value=170),\n",
    "        \"greQ\": st.number_input(\"GRE Quantitative Score\", min_value=130, max_value=170),\n",
    "        \"greA\": st.number_input(\"GRE Analytical Score\", min_value=0.0, max_value=6.0, step=0.1),\n",
    "        \"normalized_cgpa\": st.number_input(\"Normalized CGPA\", min_value=0.0, max_value=10.0, step=0.1),\n",
    "    }\n",
    "    feature_order_spec = ['major', 'researchExp', 'industryExp', 'toeflScore', 'internExp', 'greV', 'greQ', 'greA', 'normalized_cgpa']\n",
    "    input_df_spec = preprocess_input(\n",
    "        user_input, \n",
    "        categorical_features=['major'], \n",
    "        numerical_features=['researchExp', 'industryExp', 'toeflScore', 'internExp', 'greV', 'greQ', 'greA', 'normalized_cgpa'],\n",
    "        label_encoders=models['label_encoders_specialization'], \n",
    "        scaler=models['scaler_specialization'], \n",
    "        feature_order=feature_order_spec\n",
    "    )\n",
    "    \n",
    "    if st.button(\"ðŸ” Recommend Major\"):\n",
    "        recs = hybrid_recommendation(\n",
    "            input_df_spec, \n",
    "            models['rf_specialization'][0], \n",
    "            models['xgb_specialization'],\n",
    "            models['knn_specialization'], \n",
    "            models['svd_specialization'],\n",
    "            models['le_y_specialization']\n",
    "        )\n",
    "        st.success(\"ðŸŽ¯ Recommended Majors:\")\n",
    "        for r in recs:\n",
    "            st.markdown(f\"#### {r.upper()} ðŸš€\")\n",
    "            stats_df = display_specialization_stats(r, df)\n",
    "            if stats_df is not None:\n",
    "                st.table(stats_df)\n",
    "            else:\n",
    "                st.info(\"â„¹ï¸ No additional details available.\")\n",
    "\n",
    "\n",
    "\n",
    "elif page == \"University Recommendation\":\n",
    "    st.header(\"ðŸ« University Recommendation\")\n",
    "    user_input = {\n",
    "        \"ugCollege\": st.selectbox(\"Undergraduate College\", sorted(df['ugCollege'].dropna().unique())),\n",
    "        \"univ_state\": st.selectbox(\"Preferred University State\", [\"Select All\"] + sorted(df['univ_state'].unique())),\n",
    "        \"toeflScore\": st.number_input(\"TOEFL Score\", min_value=0, max_value=120),\n",
    "        \"greV\": st.number_input(\"GRE Verbal Score\", min_value=130, max_value=170),\n",
    "        \"greQ\": st.number_input(\"GRE Quantitative Score\", min_value=130, max_value=170),\n",
    "        \"greA\": st.number_input(\"GRE Analytical Score\", min_value=0.0, max_value=6.0, step=0.1),\n",
    "        \"normalized_cgpa\": st.number_input(\"Normalized CGPA\", min_value=0.0, max_value=10.0, step=0.1),\n",
    "        \"specialization_category\": st.selectbox(\"Intended Specialization\", sorted(df['specialization_category'].dropna().unique())),\n",
    "    }\n",
    "    feature_order_univ = ['ugCollege', 'specialization_category', 'toeflScore', 'greV', 'greQ', 'greA', 'normalized_cgpa']\n",
    "    input_df_univ = preprocess_input(\n",
    "        user_input, \n",
    "        categorical_features=['ugCollege', 'specialization_category'], \n",
    "        numerical_features=['toeflScore', 'greV', 'greQ', 'greA', 'normalized_cgpa'], \n",
    "        label_encoders=models['label_encoders_university'], \n",
    "        scaler=models['scaler_university'], \n",
    "        feature_order=feature_order_univ, \n",
    "        one_hot_columns=models['one_hot_columns_university']\n",
    "    )\n",
    "    \n",
    "    if st.button(\"ðŸ” Recommend Universities\"):\n",
    "        # Extract the Random Forest model from the loaded dictionary.\n",
    "        # (In training, rf_university.pkl was saved as a dict with key \"Random Forest\".)\n",
    "        rf_university_model = models[\"rf_university\"][\"Random Forest\"][0]\n",
    "        \n",
    "        # If user selects \"Select All\", pass state as None.\n",
    "        selected_state = user_input['univ_state'] if user_input['univ_state'] != \"Select All\" else None\n",
    "        \n",
    "        recommendations = hybrid_university_recommendation(\n",
    "            input_df_univ, \n",
    "            rf_university_model, \n",
    "            models['knn_university'], \n",
    "            models['svd_university'], \n",
    "            models['le_y_university'], \n",
    "            is_university=True, \n",
    "            state=selected_state,\n",
    "            one_hot_columns=models['one_hot_columns_university']\n",
    "        )\n",
    "        \n",
    "        # Prepare a dataframe for better display\n",
    "        university_data_list = []\n",
    "        \n",
    "        for rec in recommendations:\n",
    "            university_data = df[df['univName'] == rec]\n",
    "    \n",
    "            if not university_data.empty:\n",
    "                # Extract the rank and acceptance rate for the current university\n",
    "                university_rank = university_data['univName_rank'].values[0]\n",
    "                acceptance_rate = university_data['acceptance_rate'].values[0]\n",
    "                \n",
    "                # Append the data to the list\n",
    "                university_data_list.append({\n",
    "                    'University': rec.upper(),\n",
    "                    'ðŸ“Š World University Ranking': university_rank,\n",
    "                    'ðŸ“‰ Acceptance Rate': f\"{acceptance_rate}%\",\n",
    "                })\n",
    "            else:\n",
    "                # If data is missing, show a warning\n",
    "                st.warning(f\"Details for {rec} not found.\")\n",
    "        \n",
    "        # Convert the list of university data into a pandas DataFrame\n",
    "        if university_data_list:\n",
    "            university_df = pd.DataFrame(university_data_list)\n",
    "            # Reset the index and start it from 1 instead of 0\n",
    "            university_df.index = university_df.index + 1  \n",
    "            st.table(university_df)\n",
    "        else:\n",
    "            st.warning(\"No recommendations found.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
